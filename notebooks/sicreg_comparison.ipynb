{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comparación de entrenamiento estándar vs SICReg en datasets de torchvision\n",
        "\n",
        "Este notebook entrena una **ResNet18** en varios datasets de `torchvision` (MNIST, CIFAR10, CIFAR100) con:\n",
        "\n",
        "1. **Entrenamiento estándar** (cross-entropy).\n",
        "2. **Entrenamiento estándar + pérdida SICReg**.\n",
        "\n",
        "Al final se genera una tabla con los resultados de generalización y gráficos con las curvas de aprendizaje para comparar ambos métodos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports y configuración\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import math\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Device:', device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Definición de la pérdida SICReg\n",
        "\n",
        "La implementación sigue el esquema del ejemplo mínimo (SIGReg) pero usando el nombre **SICReg** para mantener la convención del enunciado.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class SICReg(nn.Module):\n",
        "    def __init__(self, knots: int = 17):\n",
        "        super().__init__()\n",
        "        t = torch.linspace(0, 3, knots, dtype=torch.float32)\n",
        "        dt = 3 / (knots - 1)\n",
        "        weights = torch.full((knots,), 2 * dt, dtype=torch.float32)\n",
        "        weights[[0, -1]] = dt\n",
        "        window = torch.exp(-t.square() / 2.0)\n",
        "        self.register_buffer('t', t)\n",
        "        self.register_buffer('phi', window)\n",
        "        self.register_buffer('weights', weights * window)\n",
        "\n",
        "    def forward(self, proj: torch.Tensor) -> torch.Tensor:\n",
        "        # proj: [V, B, D]\n",
        "        A = torch.randn(proj.size(-1), 256, device=proj.device)\n",
        "        A = A.div_(A.norm(p=2, dim=0))\n",
        "        x_t = (proj @ A).unsqueeze(-1) * self.t\n",
        "        err = (x_t.cos().mean(-3) - self.phi).square() + x_t.sin().mean(-3).square()\n",
        "        statistic = (err @ self.weights) * proj.size(-2)\n",
        "        return statistic.mean()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Modelo ResNet18 con cabeza de proyección\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class ResNet18WithHead(nn.Module):\n",
        "    def __init__(self, num_classes: int, proj_dim: int = 128):\n",
        "        super().__init__()\n",
        "        self.backbone = models.resnet18(weights=None)\n",
        "        self.backbone.fc = nn.Identity()\n",
        "        self.classifier = nn.Linear(512, num_classes)\n",
        "        self.projector = nn.Sequential(\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, proj_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        features = self.backbone(x)\n",
        "        logits = self.classifier(features)\n",
        "        proj = self.projector(features)\n",
        "        return logits, proj\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Datasets y DataLoaders\n",
        "\n",
        "Se construyen transformaciones específicas para cada dataset. Para **MNIST** se replica el canal a 3 para adaptarlo a ResNet.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "@dataclass\n",
        "class DatasetConfig:\n",
        "    name: str\n",
        "    dataset_cls: type\n",
        "    num_classes: int\n",
        "    image_size: int\n",
        "\n",
        "DATASETS = [\n",
        "    DatasetConfig('MNIST', datasets.MNIST, 10, 28),\n",
        "    DatasetConfig('CIFAR10', datasets.CIFAR10, 10, 32),\n",
        "    DatasetConfig('CIFAR100', datasets.CIFAR100, 100, 32),\n",
        "]\n",
        "\n",
        "def build_transforms(image_size: int, is_train: bool, grayscale: bool = False):\n",
        "    if is_train:\n",
        "        tfm = transforms.Compose([\n",
        "            transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "        ])\n",
        "    else:\n",
        "        tfm = transforms.Compose([\n",
        "            transforms.Resize(image_size),\n",
        "            transforms.CenterCrop(image_size),\n",
        "        ])\n",
        "\n",
        "    to_tensor = [transforms.ToTensor()]\n",
        "    if grayscale:\n",
        "        to_tensor.append(transforms.Lambda(lambda x: x.repeat(3, 1, 1)))\n",
        "    return transforms.Compose([tfm] + to_tensor)\n",
        "\n",
        "class MultiViewDataset(Dataset):\n",
        "    def __init__(self, base_dataset: Dataset, views: int, transform):\n",
        "        self.base_dataset = base_dataset\n",
        "        self.views = views\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.base_dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x, y = self.base_dataset[idx]\n",
        "        return torch.stack([self.transform(x) for _ in range(self.views)]), y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Funciones de entrenamiento y evaluación\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def evaluate(model: nn.Module, loader: DataLoader) -> float:\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            logits, _ = model(x)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    return correct / total\n",
        "\n",
        "def train_one_epoch_baseline(model, loader, optimizer):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for x, y in loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        logits, _ = model(x)\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * y.size(0)\n",
        "    return running_loss / len(loader.dataset)\n",
        "\n",
        "def train_one_epoch_sicreg(model, loader, optimizer, sicreg: SICReg, lamb: float):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for views, y in loader:\n",
        "        views = views.to(device)\n",
        "        y = y.to(device)\n",
        "        v1 = views[:, 0]\n",
        "        v2 = views[:, 1]\n",
        "        logits1, proj1 = model(v1)\n",
        "        logits2, proj2 = model(v2)\n",
        "        cls_loss = 0.5 * (F.cross_entropy(logits1, y) + F.cross_entropy(logits2, y))\n",
        "        proj = torch.stack([proj1, proj2], dim=0)\n",
        "        sicreg_loss = sicreg(proj)\n",
        "        loss = cls_loss + lamb * sicreg_loss\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * y.size(0)\n",
        "    return running_loss / len(loader.dataset)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Ejecutar experimentos\n",
        "\n",
        "Ajustá `EPOCHS`, `BATCH_SIZE` o `LAMB` según recursos.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "EPOCHS = 5\n",
        "BATCH_SIZE = 128\n",
        "LR = 1e-3\n",
        "LAMB = 0.05\n",
        "\n",
        "results: Dict[str, Dict[str, List[float]]] = {}\n",
        "summary_rows = []\n",
        "\n",
        "for cfg in DATASETS:\n",
        "    print(f'==> Dataset: {cfg.name}')\n",
        "    grayscale = cfg.name == 'MNIST'\n",
        "    train_tfm = build_transforms(cfg.image_size, is_train=True, grayscale=grayscale)\n",
        "    test_tfm = build_transforms(cfg.image_size, is_train=False, grayscale=grayscale)\n",
        "\n",
        "    train_base = cfg.dataset_cls(root='data', train=True, download=True, transform=train_tfm)\n",
        "    train_raw = cfg.dataset_cls(root='data', train=True, download=True, transform=None)\n",
        "    test_base = cfg.dataset_cls(root='data', train=False, download=True, transform=test_tfm)\n",
        "\n",
        "    baseline_loader = DataLoader(train_base, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "    test_loader = DataLoader(test_base, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "    mv_dataset = MultiViewDataset(train_raw, views=2, transform=train_tfm)\n",
        "    sicreg_loader = DataLoader(mv_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "\n",
        "    # Baseline training\n",
        "    baseline_model = ResNet18WithHead(cfg.num_classes).to(device)\n",
        "    baseline_opt = torch.optim.Adam(baseline_model.parameters(), lr=LR)\n",
        "    baseline_losses = []\n",
        "    baseline_accs = []\n",
        "    for epoch in range(EPOCHS):\n",
        "        loss = train_one_epoch_baseline(baseline_model, baseline_loader, baseline_opt)\n",
        "        acc = evaluate(baseline_model, test_loader)\n",
        "        baseline_losses.append(loss)\n",
        "        baseline_accs.append(acc)\n",
        "        print(f'  [Baseline] Epoch {epoch+1}/{EPOCHS} - loss: {loss:.4f} - acc: {acc:.4f}')\n",
        "\n",
        "    # SICReg training\n",
        "    sicreg_model = ResNet18WithHead(cfg.num_classes).to(device)\n",
        "    sicreg_opt = torch.optim.Adam(sicreg_model.parameters(), lr=LR)\n",
        "    sicreg_losses = []\n",
        "    sicreg_accs = []\n",
        "    sicreg_loss_fn = SICReg().to(device)\n",
        "    for epoch in range(EPOCHS):\n",
        "        loss = train_one_epoch_sicreg(sicreg_model, sicreg_loader, sicreg_opt, sicreg_loss_fn, LAMB)\n",
        "        acc = evaluate(sicreg_model, test_loader)\n",
        "        sicreg_losses.append(loss)\n",
        "        sicreg_accs.append(acc)\n",
        "        print(f'  [SICReg]  Epoch {epoch+1}/{EPOCHS} - loss: {loss:.4f} - acc: {acc:.4f}')\n",
        "\n",
        "    results[cfg.name] = {\n",
        "        'baseline_loss': baseline_losses,\n",
        "        'baseline_acc': baseline_accs,\n",
        "        'sicreg_loss': sicreg_losses,\n",
        "        'sicreg_acc': sicreg_accs,\n",
        "    }\n",
        "    summary_rows.append({\n",
        "        'Dataset': cfg.name,\n",
        "        'Baseline Acc (last)': baseline_accs[-1],\n",
        "        'SICReg Acc (last)': sicreg_accs[-1],\n",
        "    })\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Tabla comparativa de generalización\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Curvas de aprendizaje por dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for dataset_name, data in results.items():\n",
        "    epochs = list(range(1, len(data['baseline_acc']) + 1))\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.plot(epochs, data['baseline_acc'], label='Baseline')\n",
        "    plt.plot(epochs, data['sicreg_acc'], label='SICReg')\n",
        "    plt.title(f'Accuracy vs Epochs - {dataset_name}')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Test Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "**Notas:**\n",
        "- Para resultados más robustos aumentá `EPOCHS` y considerá usar un scheduler.\n",
        "- Podés agregar más datasets de `torchvision` extendiendo la lista `DATASETS`.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}